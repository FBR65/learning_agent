# Universeller Lernagent

Ein kinderfreundlicher Lernassistent mit Spaced Repetition System, der Reinforcement Learning verwendet, um sich an den individuellen Lernfortschritt anzupassen.

## ğŸ“¸ Screenshots

<table>
<tr>
<td width="50%">
<img src="images/upload.png" alt="Upload Interface" />
<p align="center"><strong>Upload & Import</strong></p>
</td>
<td width="50%">
<img src="images/session.png" alt="Lern-Session" />
<p align="center"><strong>Lern-Session</strong></p>
</td>
</tr>
<tr>
<td width="50%">
<img src="images/spaced.png" alt="Spaced Repetition" />
<p align="center"><strong>Spaced Repetition</strong></p>
</td>
<td width="50%">
<img src="images/help.png" alt="Hilfe" />
<p align="center"><strong>Hilfe & Anleitung</strong></p>
</td>
</tr>
</table>

## ğŸ¯ Kernkonzept

Dieser Lernagent implementiert ein universelles Framework fÃ¼r verschiedene Lernszenarien. Das System:
- Passt sich dynamisch an den Lernfortschritt an
- Verwendet Spaced Repetition fÃ¼r optimales Langzeitlernen
- WÃ¤hlt optimale Aufgaben basierend auf dem aktuellen Wissensstand
- Gibt gezielte Hinweise und Feedback
- Optimiert die Lerngeschwindigkeit durch intelligente Schwierigkeitsanpassung

## ğŸ—ï¸ Architektur

### Komponenten
1. **Lernszenarien**: Modulare Definition von Lerninhalten (CSV/JSON/XML-Import)
2. **Spaced Repetition System**: SM-2 Algorithmus fÃ¼r optimale Wiederholung
3. **RL-Agent**: Trainierter Agent mit DQN/A2C/PPO Algorithmen (automatisch)
4. **FastAPI Backend**: REST-API fÃ¼r alle Lernfunktionen
5. **Web-Interface**: Modernes HTML/JavaScript Frontend
6. **Szenario-Manager**: Import und Verwaltung von Lernszenarien

### UnterstÃ¼tzte Lernszenarien
- **Latein**: Vokabeln und Grammatik fÃ¼r AnfÃ¤nger
- **Python**: Programmierung Grundlagen
- **Mathematik**: Grundrechenarten und Algebra
- **Eigene Inhalte**: CSV/JSON/XML Import-UnterstÃ¼tzung

## ğŸš€ Installation und Setup

### Voraussetzungen
- Python >= 3.11
- uv Package Manager (empfohlen) oder pip

### Installation
```bash
# Clone/Download das Projekt
cd learning_agent

# Virtuelle Umgebung aktivieren (Windows PowerShell)
.venv\Scripts\activate

# AbhÃ¤ngigkeiten installieren
uv sync
```

## ğŸ“– Verwendung

### Web-Interface (Empfohlen)
```bash
# Einfachster Start - Ã¶ffnet automatisch das Web-Interface
python main.py

# Oder explizit das Web-Interface starten
python main.py --web

# Oder direkt die API starten
python -m src.learning_agent.api
```
Das Web-Interface Ã¶ffnet sich automatisch im Browser unter `http://localhost:8001`

### CLI-Funktionen (Erweitert)
```bash
# Beispiel-Szenarien erstellen
python main.py --create-scenarios

# VerfÃ¼gbare Szenarien anzeigen
python main.py --list-scenarios

# Agent trainieren (fÃ¼r Entwickler)
python main.py --train latein_anfaenger --algorithm DQN --timesteps 10000
```

### ğŸ³ Docker (Containerisiert)
```bash
# Mit Docker Compose (empfohlen)
docker-compose up -d

# Oder manuell mit Docker
docker build -t learning-agent .
docker run -p 8001:8001 -v ./models:/app/models -v ./scenarios:/app/scenarios learning-agent
```

### ğŸš€ GPU-UnterstÃ¼tzung (fÃ¼r Training)
```bash
# GPU-Version mit Docker Compose
docker-compose --profile gpu up -d
```

## ğŸ® Web-Interface Funktionen

![Learning Agent Upload Interface](images/upload.png)

### 1. Upload & Import
- **Datei-Upload**: CSV, JSON, XML, Excel-Dateien
- **Format-Anleitung**: Integrierte Hilfe fÃ¼r korrekte Dateiformate
- **Automatisches Training**: System wird nach Upload automatisch vorbereitet
- **Beispiel-Szenarien**: Vorgefertigte Lernsets zum Ausprobieren

![Szenario Auswahl](images/szenario.png)

### 2. Szenario-Auswahl
- Anzeige aller verfÃ¼gbaren Lernszenarien
- Detaillierte Informationen zu jedem Szenario
- Einfache Auswahl fÃ¼r sofortigen Start

![Lern-Session](images/session.png)

### 3. Lern-Session
- Interaktive Lernsessions mit Frage-Antwort-System
- Echtzeit-Anpassung der Schwierigkeit
- Fortschrittsverfolgung und Statistiken
- Anti-Cheat-System fÃ¼r ehrliches Lernen

![Spaced Repetition](images/spaced.png)

### 4. Spaced Repetition
- **SM-2 Algorithmus**: Wissenschaftlich bewÃ¤hrtes Wiederholungssystem
- **Intelligente Terminierung**: Karten werden optimal zeitlich verteilt
- **QualitÃ¤tsbewertung**: 6-stufiges Bewertungssystem (0-5)
- **Fortschrittsanzeige**: Klare RÃ¼ckmeldung Ã¼ber Wiederholungsintervalle

![Hilfe und Anleitung](images/help.png)

### 5. Hilfe & Anleitung
- **Erste Schritte**: Schritt-fÃ¼r-Schritt Anleitung
- **Dateiformat-Hilfe**: Detaillierte ErklÃ¤rungen fÃ¼r Import-Formate
- **Spaced Repetition ErklÃ¤rung**: Wie das Lernsystem funktioniert
- **Lerntipps**: PÃ¤dagogisch wertvolle Hinweise

## ğŸ§  Spaced Repetition Details

### SM-2 Algorithmus
Das System verwendet den bewÃ¤hrten SM-2 (SuperMemo 2) Algorithmus:
- **Neue Karten**: Erste Wiederholung nach 1 Tag
- **Erfolgreiche Karten**: Intervalle steigen (1 â†’ 6 â†’ 13+ Tage)
- **Schwierige Karten**: Sofortige Wiederholung bei Fehlern
- **Anpassung**: Einfachheitsfaktor passt sich an Leistung an

### Bewertungssystem
- **0 - Blackout**: Kompletter Blackout
- **1 - Sehr schwer**: Inkorrekt, aber erinnert
- **2 - Schwer**: Korrekt mit groÃŸer Schwierigkeit
- **3 - Normal**: Korrekt mit etwas Schwierigkeit
- **4 - Leicht**: Korrekt ohne Schwierigkeit
- **5 - Perfekt**: Perfekt und schnell

## ğŸ§  Reinforcement Learning Details

### Automatisches Training
Das System trainiert sich automatisch beim Upload neuer Szenarien:
- **Robustes Training**: Mehrere Versuche mit steigender IntensitÃ¤t
- **QualitÃ¤tskontrolle**: Mindest-Performance-Threshold
- **Transparenz**: Benutzer sehen nur "System bereit" - keine technischen Details

### State (Zustand des Lernenden)
- Erfolgsraten pro Kategorie
- Durchschnittliche Antwortzeiten
- Anzahl verwendeter Hinweise
- Aufeinanderfolgende richtige/falsche Antworten
- GeschÃ¤tzte FÃ¤higkeiten (Item Response Theory)

### Actions (Agent-Aktionen)
- Aufgabe mit spezifischer Schwierigkeit stellen
- Hinweis geben
- Feedback bereitstellen
- Schwierigkeit anpassen

### Reward (Belohnung)
- +1.0 fÃ¼r richtige Antworten
- +0.5 Bonus fÃ¼r optimale Erfolgsrate (70-80%)
- +0.2 Bonus fÃ¼r schnelle Antworten
- -0.5 fÃ¼r falsche Antworten
- -0.1 fÃ¼r Hinweise
- ZusÃ¤tzliche Strafen/Boni basierend auf Lernfortschritt

### Algorithmen
- **DQN**: Deep Q-Network (Standard)
- **A2C**: Advantage Actor-Critic
- **PPO**: Proximal Policy Optimization

## ğŸ“ Projektstruktur

```
learning_agent/
â”œâ”€â”€ main.py                          # Haupteinstiegspunkt (CLI + Web-Interface)
â”œâ”€â”€ pyproject.toml                   # Projekt-Konfiguration
â”œâ”€â”€ docker-compose.yml               # Docker-Konfiguration
â”œâ”€â”€ docker-entrypoint.sh             # Container-Start-Skript
â”œâ”€â”€ src/learning_agent/              # Hauptcode
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                      # FastAPI Server
â”‚   â”œâ”€â”€ models.py                   # Datenmodelle (Pydantic)
â”‚   â”œâ”€â”€ environment.py              # Gymnasium-Umgebung
â”‚   â”œâ”€â”€ agent.py                    # RL-Agent (Stable Baselines3)
â”‚   â”œâ”€â”€ scenario_manager.py         # Szenario-Verwaltung
â”‚   â”œâ”€â”€ scenario_importer.py        # Multi-Format Import (CSV/JSON/XML)
â”‚   â”œâ”€â”€ spaced_repetition.py        # SM-2 Spaced Repetition System
â”‚   â”œâ”€â”€ auto_training.py           # Automatisches Training-Management
â”‚   â”œâ”€â”€ ui.py                      # Legacy Streamlit Interface
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ index.html             # Modernes Web-Frontend
â”œâ”€â”€ scenarios/                      # JSON-Szenario-Dateien
â”œâ”€â”€ models/                        # Trainierte RL-Modelle
â””â”€â”€ data/                         # Lernfortschritt-Daten
    â””â”€â”€ spaced_repetition/        # Spaced Repetition Karten-Datenbank
```

## ğŸ”§ Eigene Szenarien erstellen

### CSV-Format (Empfohlen)
```csv
Frage,Antwort,Kategorie,Schwierigkeit
"Was bedeutet 'puer'?","Junge","Latein",1
"Was bedeutet 'puella'?","MÃ¤dchen","Latein",1
"Was ist 2+2?","4","Mathematik",1
```

### JSON-Format (Erweitert)
```json
{
  "name": "mein_szenario",
  "description": "Beschreibung des Lernszenarios",
  "version": "1.0",
  "categories": ["Kategorie1", "Kategorie2"],
  "tasks": [
    {
      "id": "task_001",
      "question": "Frage?",
      "answer": "Antwort",
      "task_type": "free_text",
      "difficulty": 1,
      "category": "Kategorie1",
      "hints": ["Hinweis 1", "Hinweis 2"]
    }
  ]
}
```

### XML-Format
```xml
<?xml version="1.0" encoding="UTF-8"?>
<scenario>
    <name>mein_szenario</name>
    <description>Beschreibung</description>
    <tasks>
        <task>
            <question>Frage?</question>
            <answer>Antwort</answer>
            <category>Kategorie1</category>
            <difficulty>1</difficulty>
        </task>
    </tasks>
</scenario>
```

### Task-Typen
- `free_text`: Freitext-Antwort
- `multiple_choice`: Multiple Choice
- `translation`: Ãœbersetzung
- `code_completion`: Code-VervollstÃ¤ndigung
- `fill_in_blank`: LÃ¼ckentext

### Schwierigkeitsgrade
- `1`: AnfÃ¤nger
- `2`: Fortgeschritten
- `3`: Experte
- `4`: Meister

## ğŸ¯ Training-Tipps

### Optimale Parameter (automatisch konfiguriert)
- **DQN**: Gut fÃ¼r diskrete Aktionen, stabil
- **A2C**: Schneller als DQN, weniger Speicher
- **PPO**: Beste Balance zwischen Performance und StabilitÃ¤t

### Training Duration (automatisch optimiert)
- **Einfache Szenarien**: 10,000+ Timesteps
- **Komplexe Szenarien**: 20,000-30,000 Timesteps
- **Robustes System**: Mehrere Versuche bis Erfolg

## ğŸ” API Endpunkte

### Hauptendpunkte
- `GET /`: Web-Interface
- `GET /api/scenarios`: VerfÃ¼gbare Szenarien
- `POST /api/upload-scenario`: Szenario-Upload
- `POST /api/load-scenario`: Szenario laden
- `POST /api/start-session`: Lernsession starten
- `POST /api/submit-answer`: Antwort einreichen
- `GET /api/spaced-repetition/due`: FÃ¤llige Wiederholungen
- `POST /api/spaced-repetition/check-answer/{card_id}`: Antwort prÃ¼fen
- `POST /api/spaced-repetition/review`: Wiederholung bewerten
- `GET /api/health`: Gesundheitscheck

## ğŸ” Troubleshooting

### HÃ¤ufige Probleme
1. **"LÃ¤dt Szenarien..."**: Server neu starten oder Beispiel-Szenarien erstellen
2. **"Szenario nicht gefunden"**: Erstelle Beispiel-Szenarien Ã¼ber Upload-Tab
3. **Upload-Fehler**: PrÃ¼fe Dateiformat entsprechend der Anleitung im Hilfe-Tab
4. **Training-Probleme**: System trainiert automatisch - bei Problemen Server neu starten

### Performance-Optimierung
- Verwende CSV-Format fÃ¼r einfachste Uploads
- Nutze Docker fÃ¼r isolierte Umgebung
- GPU-UnterstÃ¼tzung fÃ¼r groÃŸe DatensÃ¤tze

## ğŸ¤ Erweiterungen

### Neue Algorithmen hinzufÃ¼gen
1. Erweitere `LearningAgent.create_model()`
2. FÃ¼ge neuen Algorithmus zu den Optionen hinzu
3. Teste mit verschiedenen Szenarien

### Neue Import-Formate
1. Erweitere `ScenarioImporter` in `scenario_importer.py`
2. Implementiere neue Parser-Methoden
3. Teste Import-FunktionalitÃ¤t

### Integration von externen APIs
- Sprachmodelle fÃ¼r Feedback-Generierung
- Text-to-Speech fÃ¼r Audio-Feedback
- Adaptive Testing Algorithmen

## ğŸ“Š Metriken und Evaluation

### Spaced Repetition Metriken
- Retention Rate (Behaltensrate)
- Review Accuracy (Wiederholungsgenauigkeit)
- Optimal Interval Adherence (Intervalltreue)
- Learning Velocity (Lerngeschwindigkeit)

### Agent-Performance
- Episode Rewards
- Convergence Rate
- Final Success Rate

### Lerner-Performance  
- Accuracy over Time
- Learning Velocity
- Long-term Retention


## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Einfachheit

Das System wurde speziell fÃ¼r eine einfache Nutzung, auch durch Kinder, optimiert:
- **Einfache Navigation**: Nur wesentliche Funktionen sichtbar
- **Klare Anweisungen**: Schritt-fÃ¼r-Schritt FÃ¼hrung
- **Automatische Prozesse**: Kein manuelles Training erforderlich
- **VerstÃ¤ndliche RÃ¼ckmeldungen**: Keine technischen Fehlermeldungen
- **Sichere Umgebung**: Lokale AusfÃ¼hrung, keine Internetverbindung nÃ¶tig

## ğŸ“„ Lizenz

AGPLv3 License - siehe LICENSE.md

